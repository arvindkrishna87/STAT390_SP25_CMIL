{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edadd12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math \n",
    "from shapely.geometry import Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from matplotlib import colors\n",
    "from scipy.signal import argrelextrema\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a0609d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extension_factor = 1.1\n",
    "step_size = 2\n",
    "max_width = 2048\n",
    "overlap_thresh = 0.3\n",
    "weight_epithelium_coverage = 0.8\n",
    "weight_background_pixels = 0.2\n",
    "sigma_factor = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8fae08",
   "metadata": {},
   "source": [
    "## Base Patching Algorithm (dated 04/27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcae061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_curvature_complexity(points):\n",
    "    \"\"\"\n",
    "    Estimate complexity of a contour based on curvature variations.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(points)<5:\n",
    "        return 1\n",
    "    \n",
    "    diffs=np.gradient(points, axis=0)\n",
    "    curvature=np.linalg.norm(np.gradient(diffs,axis=0),axis=1)\n",
    "\n",
    "    # Count number of local maxima in curvature (sharp points)\n",
    "    peaks=argrelextrema(curvature, np.greater)[0]\n",
    "    \n",
    "    #Return peaks/points for rough approx of sharp changes\n",
    "    return len(peaks)/len(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c3ceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_external_contours(binary_image):\n",
    "    '''find all ext`ernal contours of an image'''\n",
    "\n",
    "    contours,hierarchy=cv2.findContours(binary_image,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    #This can be used to alter the order contour points are processed in while maintaining order\n",
    "        #Think [1,2,3,4,5]->[4,5,1,2,3]\n",
    "        #Set to 0 for no effect, check np documentation for more info\n",
    "    return [np.roll(contour,0,axis=0) for contour in contours if len(contour)>1]\n",
    "\n",
    "\n",
    "def gaussian_normals(contours):\n",
    "    #Initialize list for final normals\n",
    "    all_normals=[]\n",
    "    smooth=[]\n",
    "\n",
    "    #Loop through all contours\n",
    "    for contour in contours:\n",
    "        #Reshape contour into point pairings\n",
    "        points=contour.reshape(-1,2).astype(np.float32)\n",
    "        \n",
    "        #Define sigma paramter(std for Gaussian Kernel from contour length)\n",
    "        #Higher value of sigma means more aggressive smoothing\n",
    "        #sigma,smoothed=estimate_sigma(points,1,1e-5,60)\n",
    "        sigma=max(len(contour)*estimate_curvature_complexity(points)//sigma_factor,1)\n",
    "        smoothed=gaussian_filter1d(points,sigma,axis=0, truncate = 100)\n",
    "        print(f'Sigma of : {sigma}')\n",
    "        #Apply Gaussian smoothing to X and Y values, attempting to remove noise from the contour\n",
    "        #smoothed=np.apply_along_axis(lambda x: gaussian_filter1d(x,sigma,mode='reflect'),axis=0,arr=points)\n",
    "        #Calculate gradients of X and Y for use then finding the tangent\n",
    "        gradients=np.gradient(smoothed,axis=0)\n",
    "        #Find vector norms of tangent vectors\n",
    "        all_norms=np.linalg.norm(gradients,axis=1,keepdims=True)\n",
    "        #Divide tangents by norms with numerical stability\n",
    "        tangent_unit=gradients/(all_norms+1e-8)\n",
    "        #Initialize normals\n",
    "        normals=np.zeros_like(tangent_unit)\n",
    "        \n",
    "        normals = np.column_stack((-tangent_unit[:, 1], tangent_unit[:, 0]))\n",
    "        all_normals.append(normals)\n",
    "        smooth.append(smoothed.reshape(-1,1,2).astype(np.int32))\n",
    "\n",
    "    return all_normals,smooth\n",
    "\n",
    "\n",
    "def calculate_patch_corners(point, normal, binary_image, extension_factor=1.0, step_size=4, max_length=2048):\n",
    "    \"\"\"\n",
    "    Calculate the corners of a square patch using epithelium width along the normal.\n",
    "\n",
    "    Args:\n",
    "        point (np.ndarray): The point on the contour.\n",
    "        normal (np.ndarray): The normal vector at the point.\n",
    "        binary_image (np.ndarray): Binary mask of the tissue.\n",
    "        extension_factor (float): Factor to slightly enlarge the patch (e.g., 1.1 for 10% increase).\n",
    "        step_size (int): Step size for checking tissue boundaries along the normal.\n",
    "        max_length (int): Maximum distance to search for epithelium width.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The four corners of the square patch.\n",
    "        int: The computed patch height.\n",
    "    \"\"\"\n",
    "    height, width = binary_image.shape\n",
    "    point = point.astype(int)\n",
    "\n",
    "    # generating forward and backward points along the normal\n",
    "    steps = np.arange(0, max_length, step_size)[:, None]\n",
    "    points = np.clip(point - steps * normal, 0, [width - 1, height - 1]).astype(int)\n",
    "\n",
    "    # extracting pixel values along the normal path\n",
    "    values = binary_image[points[:, 1], points[:, 0]]\n",
    "\n",
    "    # finding the first background pixel (where value == 0)\n",
    "    stop = np.where(values == 0)[0]\n",
    "\n",
    "    # computing distances\n",
    "    width = stop[0] * step_size if stop.size > 0 else max_length\n",
    "\n",
    "    # computing total epithelium width and adjust for stroma extension\n",
    "    extended_length = int(width * extension_factor)\n",
    "    half_size = extended_length // 2 \n",
    "\n",
    "    # computing tangent vector (perpendicular to normal)\n",
    "    tangent = np.array([-normal[1], normal[0]])\n",
    "\n",
    "    # defining square corners (same logic as `calculate_square_corners`)\n",
    "    corners = np.array([\n",
    "        point + (tangent * half_size),\n",
    "        point - (tangent * half_size),\n",
    "        point - (tangent * half_size) - (normal * extended_length),\n",
    "        point + (tangent * half_size) - (normal * extended_length)\n",
    "    ])\n",
    "\n",
    "    return corners, extended_length\n",
    "\n",
    "\n",
    "def calculate_square_overlap(square1,square2):\n",
    "    '''Calculate overlap ratio between squares'''\n",
    "\n",
    "    square1=Polygon(square1)\n",
    "    square2=Polygon(square2)\n",
    "\n",
    "    if not square1.intersects(square2):\n",
    "        return 0\n",
    "    \n",
    "    intersection_area=square1.intersection(square2).area\n",
    "    smallest_area=min(square1.area,square2.area)\n",
    "    return intersection_area/(smallest_area+1e-8)\n",
    "\n",
    "\n",
    "\n",
    "def create_smarter_squares(contours,normals,binary_image,overlap_thresh):\n",
    "    '''Create squares that meet overlap thresh with last square'''\n",
    "    return_squares=[]\n",
    "    return_patch_length = []\n",
    "    \n",
    "    #Loop over all contours and get corresponding normals to point\n",
    "    for contour, contour_normals in zip(contours,normals):\n",
    "        points=contour.reshape(-1,2)\n",
    "        squares=[]\n",
    "        patch_length = []\n",
    "        last_square=None\n",
    "\n",
    "        #Go over points, evaluating if next square's corner falls outside of range of last square\n",
    "        for i,point in enumerate(points):\n",
    "\n",
    "            corners,length=calculate_patch_corners(point,contour_normals[i],binary_image)\n",
    "            overlap_thresh_size_fn = min(0.8,overlap_thresh + max((length - 100)*1.5*overlap_thresh/900,0))\n",
    "            \n",
    "            #Prevent poorly sized squares\n",
    "            #Finding rough area approximation in terms of patch length\n",
    "            side_length = np.sqrt(cv2.contourArea(contour))\n",
    "            #Approximately: Want squares less than 50% of contour area, and minimum of 2% area\n",
    "            if length<side_length*0.02:\n",
    "                continue\n",
    "            #Check to see if first square and check agaisnt last square to prevent long loop\n",
    "            elif last_square is not None and calculate_square_overlap(last_square,corners)>overlap_thresh_size_fn:\n",
    "                if Polygon(last_square).area>Polygon(corners).area and calculate_square_overlap(last_square,corners)>.98:\n",
    "                    squares[-1]=corners\n",
    "                    last_square=corners\n",
    "                    continue\n",
    "                continue\n",
    "\n",
    "            #Check agasint all squares, prevents issues of larger patches covering thin sections of epithelium next to large ones \n",
    "            elif any(calculate_square_overlap(corners, square)>overlap_thresh_size_fn for square in squares)==True:\n",
    "                continue\n",
    "        \n",
    "            squares.append(corners)\n",
    "            patch_length.append(length)\n",
    "            last_square=corners\n",
    "        return_squares.append(squares)\n",
    "        return_patch_length.append(patch_length)\n",
    "    return return_squares, return_patch_length\n",
    "\n",
    "def draw_squares(image,squares_list,color=[255,0,0],thickness=20):\n",
    "    '''Draw squares on image'''\n",
    "\n",
    "    result=image.copy()\n",
    "\n",
    "    for squares in squares_list:\n",
    "        for square in squares:\n",
    "            points=square.astype(np.int32)\n",
    "            cv2.polylines(result,[points],isClosed=True,color=color,thickness=thickness)\n",
    "        \n",
    "    return result\n",
    "\n",
    "# Function to draw patches\n",
    "def draw_patches(image, patch_list, color = [255,0,0], thickness = 20):\n",
    "    patches_on_slice = image.copy()\n",
    "    for squares in patch_list:\n",
    "        for square in squares:\n",
    "            points=square.astype(np.int32)\n",
    "            cv2.polylines(patches_on_slice,[points],isClosed=True,color=color,thickness=thickness)\n",
    "    return patches_on_slice\n",
    "\n",
    "\n",
    "\n",
    "def process_contours(image,binary_image,overlap_thresh):\n",
    "    \"\"\"\n",
    "    Main function to process multiple contours and generate aligned squares along them.\n",
    "    \n",
    "    Args:\n",
    "        image (np.ndarray): Original image\n",
    "        binary_image (np.ndarray): Binary mask of the shapes\n",
    "        overlap_thresh (float): Maximum allowed overlap between squares        \n",
    "    Returns:\n",
    "        tuple: (processed image, contours, squares_list)\n",
    "    \"\"\"\n",
    "    contours=find_external_contours(binary_image)\n",
    "    if not contours:\n",
    "        return TypeError('No contours found')\n",
    "    \n",
    "    #Condition check for square creation\n",
    "    #normals=calculate_contour_normals(contours,smoothing_size)\n",
    "    normals,smooth=gaussian_normals(contours)\n",
    "    #normals,smooth=fourier_normals(contours,0.999)\n",
    "    final_squares_list, patch_length_list = create_smarter_squares(contours,normals,binary_image,overlap_thresh=overlap_thresh)\n",
    "    tissue_slice = cv2.cvtColor(cv2.imread(image), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    result = draw_squares(tissue_slice,final_squares_list)\n",
    "    #Visualzie smoothed contour\n",
    "\n",
    "    try:\n",
    "        cv2.drawContours(result,smooth,-1,(0,255,0),30)\n",
    "    except:\n",
    "        print('No smoothed contour to show')\n",
    "    \n",
    "    return result, contours, final_squares_list, normals, patch_length_list\n",
    "\n",
    "# Carried over functions\n",
    "\n",
    "def empty_folder():\n",
    "    # delete everything out of directory\n",
    "    output_folder = 'testing_slices/patch_outputs'\n",
    "    if not os.path.exists(output_folder):  # Check if folder exists\n",
    "        os.makedirs(output_folder)  # Create folder if it doesn't exist\n",
    "    for file in os.listdir(output_folder):\n",
    "        file_path = os.path.join(output_folder, file)\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            os.rmdir(file_path)\n",
    "\n",
    "# Export patched slice into a new folder \n",
    "def export_patched_slice(patched_slice_name, selected_patches_on_slice):\n",
    "\n",
    "    output_folder = os.path.join('testing_slices', 'patch_images')\n",
    "    if not os.path.exists(output_folder):  # Check if folder exists\n",
    "        os.makedirs(output_folder)  # Create folder if it doesn't exist\n",
    "\n",
    "    output_path = os.path.join(output_folder, os.path.basename(patched_slice_name))\n",
    "    cv2.imwrite(output_path, cv2.cvtColor(selected_patches_on_slice, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "# Calculate performance metrics\n",
    "def calculate_metrics(epithelium_mask_2D, all_selected_patches):\n",
    "\n",
    "    num_patches = len(np.vstack(all_selected_patches))\n",
    "\n",
    "    total_epithelium_pixels = (epithelium_mask_2D > 0).sum()\n",
    "    patch_mask = np.zeros_like(epithelium_mask_2D, dtype=np.uint8)\n",
    "\n",
    "    #For all patches in all contours, use them to create a mask\n",
    "    for contour_patches in all_selected_patches:\n",
    "        for patch in contour_patches:\n",
    "            patch = np.array(patch,dtype = np.int32).reshape(-1, 1, 2)\n",
    "            cv2.fillPoly(patch_mask, [patch], 255)\n",
    "\n",
    "    number_of_patch_mask_pixels = np.count_nonzero(patch_mask > 0)\n",
    "\n",
    "    covered_epithelium_pixels = np.count_nonzero((patch_mask > 0) & (epithelium_mask_2D > 0))\n",
    "    covered_background_pixels = np.count_nonzero((patch_mask > 0) & (epithelium_mask_2D == 0))\n",
    "\n",
    "    total_epithelium_coverage = (covered_epithelium_pixels / total_epithelium_pixels*100)\n",
    "    background_pixel_percent = (covered_background_pixels / number_of_patch_mask_pixels*100)\n",
    "    score = weight_epithelium_coverage*total_epithelium_coverage + weight_background_pixels*(100 - background_pixel_percent)\n",
    "\n",
    "    # Exporting performance metrics and parameter values\n",
    "    metrics = pd.DataFrame({'Metric':['num_patches','total_epithelium_coverage', 'background_pixel_percent',\n",
    "                        'score', 'extension_factor', 'step_size',\n",
    "                        'max_width', 'overlap_threshold'], \n",
    "                'Value':[num_patches, total_epithelium_coverage, background_pixel_percent, score, \n",
    "                        extension_factor, step_size, max_width, overlap_thresh]})\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def find_edges(all_selected_patches):\n",
    "    all_points = np.vstack(all_selected_patches[0])\n",
    "\n",
    "    edges = {'min_x': np.min(all_points[:, 0]),\n",
    "             'max_x': np.max(all_points[:, 0]),\n",
    "             'min_y': np.min(all_points[:, 1]),\n",
    "             'max_y': np.max(all_points[:, 1])}\n",
    "\n",
    "    return edges\n",
    "\n",
    "def add_padding(image, edges):\n",
    "        \n",
    "    height, width, channels = image.shape\n",
    "\n",
    "    if edges['min_x'] < 0:\n",
    "        left = math.ceil(np.abs(edges['min_x']))\n",
    "    else: left = 0\n",
    "\n",
    "    if edges['max_x'] > width:\n",
    "        right = math.ceil(edges['max_x'] - width)\n",
    "    else: right = 0\n",
    "\n",
    "    if edges['min_y'] < 0:\n",
    "        top = math.ceil(np.abs(edges['min_y']))\n",
    "    else: top = 0\n",
    "\n",
    "    if edges['max_y'] > height:\n",
    "        bottom = math.ceil(edges['max_y'] - height)\n",
    "    else: bottom = 0\n",
    "\n",
    "    new_width = width + right + left\n",
    "    new_height = height + top + bottom\n",
    "    \n",
    "\n",
    "    # compute the padding color using the mode pixel value\n",
    "    threshold = 150\n",
    "    mask = np.all(image>threshold, axis = -1)\n",
    "    if np.any(mask):\n",
    "        bright_pixels = image[mask]\n",
    "        if np.issubdtype(image.dtype,np.integer):\n",
    "            dims = (np.iinfo(image.dtype).max + 1,) * channels\n",
    "            combined = np.ravel_multi_index(bright_pixels.T,dims)\n",
    "            unique_vals, counts = np.unique(combined, return_counts = True)\n",
    "            mode_val = unique_vals[np.argmax(counts)]\n",
    "            mode_color = np.array(np.unravel_index(mode_val, dims)).astype(image.dtype)\n",
    "            pad_color = mode_color.flatten()\n",
    "        else:\n",
    "            pixels, counts = np.unique(bright_pixels, axis = 0, return_counts = True)\n",
    "            pad_color = pixels[np.argmax(counts)]\n",
    "    else:\n",
    "        pad_color = np.array([threshold] * channels , dtype = image.dtype)\n",
    "\n",
    "\n",
    "    padded_image = np.ones((new_height, new_width, channels), dtype=image.dtype) * pad_color\n",
    "\n",
    "    # Insert the original image into the array of updated dimensions\n",
    "    padded_image[top:top + height, left:left + width] = image\n",
    "\n",
    "\n",
    "    return padded_image, right, left, top, bottom\n",
    "\n",
    "# Shift patches by padding amount\n",
    "def shift_patches(padded_image, all_selected_patches, left, top):\n",
    "\n",
    "    all_points = np.vstack(all_selected_patches)\n",
    "\n",
    "    shift_x = left\n",
    "    shift_y = top\n",
    "    shift_array = np.array([shift_x, shift_y])\n",
    "    shifted_points = all_points + shift_array\n",
    "    shifted_points = np.vstack(shifted_points)\n",
    "    shifted_points = np.split(shifted_points, len(shifted_points) // 4)\n",
    "    shifted_points = [shifted_points]   \n",
    "\n",
    "    shifted_patches_on_slice = draw_patches(padded_image, shifted_points)\n",
    "\n",
    "    return shifted_patches_on_slice, shifted_points\n",
    "\n",
    "# edited to \n",
    "def show_shifted_patches(image, padded_image, all_selected_patches, shifted_patches_on_slice, binary_image):\n",
    "    # Convert grayscale mask to RGB for overlaying patches\n",
    "    mask_rgb = cv2.cvtColor(binary_image, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # Plot the original image and the patched mask side by side\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    result = draw_patches(image,all_selected_patches)\n",
    "    mask = draw_patches(mask_rgb,all_selected_patches)\n",
    "    #mask = mask_rgb\n",
    "    axes[0].imshow(result)\n",
    "    axes[0].set_title(\"Original Image\")\n",
    "    axes[0].axis(\"off\")\n",
    "    axes[1].imshow(mask)\n",
    "    axes[1].set_title(\"Grayscale Mask with Patches\")\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    result = cv2.hconcat([result,mask])\n",
    "    return result\n",
    "\n",
    "def extract_square_images(image, points):\n",
    "    \n",
    "    patch_images = []\n",
    "    square_list = np.vstack(points)\n",
    "    coords = []\n",
    "\n",
    "    for square in square_list:\n",
    "\n",
    "        # create an empty mask with white inside just the square's region\n",
    "        square = square.astype(np.int32)\n",
    "        square.reshape((-1,1,2)) # bc cv2.fillpoly expects points to be in shape (N,1,2)\n",
    "        mask = np.zeros(image.shape[:2],dtype = np.uint8)\n",
    "        cv2.fillPoly(mask, [square], 255)\n",
    "\n",
    "        # Apply the mask to the image\n",
    "        masked_image = cv2.bitwise_and(image, image, mask = mask)\n",
    "\n",
    "        # uncomment to see placement of patch within the entire slice image \n",
    "        # plt.imshow(masked_image)\n",
    "        # plt.show()\n",
    "\n",
    "        # Crop the image around the rotated square (will have black space due to rotation)\n",
    "        x_min = np.min(square[:, 0])\n",
    "        x_max = np.max(square[:, 0])\n",
    "        y_min = np.min(square[:, 1])\n",
    "        y_max = np.max(square[:, 1])\n",
    "        cropped_image = masked_image[y_min:y_max, x_min:x_max]\n",
    "        \n",
    "        coords.append((x_min, y_min, x_max, y_max))\n",
    "\n",
    "        # rotate the cropped image to be parallel to the xy axis\n",
    "        # calculate the angle the patch needs to be rotated by\n",
    "        point1 = square[0]  # top-left corner\n",
    "        point2 = square[1]  # top-right corner\n",
    "        vector = point2 - point1\n",
    "        angle_degrees = np.arctan2(vector[1], vector[0]) * (180.0 / np.pi) - 180\n",
    "\n",
    "        # Get the center of the cropped image\n",
    "        center = (int((x_max - x_min)) // 2, int((y_max - y_min)) // 2)\n",
    "\n",
    "        # Create the rotation matrix to rotate around the center\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(center, angle_degrees, 1.0) # 1.0 means image wont be scaled\n",
    "\n",
    "        # Rotate the cropped image to make it parallel to xy axis\n",
    "        if cropped_image.shape[0] > 0 and cropped_image.shape[1] > 0:\n",
    "            rotated_patch = cv2.warpAffine(cropped_image, \n",
    "                                        rotation_matrix,\n",
    "                                        (cropped_image.shape[1], cropped_image.shape[0]))  # output image size\n",
    "        else:\n",
    "            print(\"Cropped image is empty, skipping rotation.\")\n",
    "\n",
    "        # remove the extra black pixels around the edges\n",
    "        gray = cv2.cvtColor(rotated_patch, cv2.COLOR_BGR2GRAY)\n",
    "        _, thresh = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        x, y, w, h = cv2.boundingRect(contours[0])\n",
    "        cropped_img = rotated_patch[y:y+h, x:x+w]\n",
    "\n",
    "        patch_images.append(cropped_img)\n",
    "    \n",
    "    return patch_images, coords\n",
    "\n",
    "def save_patches(patch_images, slice_name):\n",
    "    # Ensure output directory exists\n",
    "    output_folder = os.path.join(\"testing_slices\",\"patch_outputs\")\n",
    "    if not os.path.exists(output_folder):  # Check if folder exists\n",
    "        os.makedirs(output_folder)  # Create folder if it doesn't exist\n",
    "    # Clean file name\n",
    "    file_name = os.path.basename(slice_name).replace('mask', '').replace('.png', '')\n",
    "    \n",
    "    # Save patches\n",
    "    for i, patch in enumerate(patch_images):\n",
    "        if isinstance(patch, np.ndarray):\n",
    "            output_path = os.path.join(output_folder, f\"{file_name}_patch{i}.png\")\n",
    "            cv2.imwrite(output_path, patch)\n",
    "\n",
    "def patching_export(binary, slice_name, slice_details, stain_images):\n",
    "    \" processes tissue slice to create and export patches\"\n",
    "    \n",
    "    result, contours, final_squares, normals, patch_length = process_contours(slice_details, binary, overlap_thresh)    \n",
    "\n",
    "    # find edges and add padding\n",
    "    edges = find_edges(final_squares)\n",
    "    tissue_slice = cv2.cvtColor(cv2.imread(slice_details), cv2.COLOR_BGR2RGB)\n",
    "    padded_image, right, left, top, bottom = add_padding(tissue_slice, edges)\n",
    "    _, shifted_points = shift_patches(padded_image, final_squares, left, top)\n",
    "    shifted_points = [tuple(pt[0]) if isinstance(pt, np.ndarray) and pt.ndim == 2 else tuple(pt) for pt in shifted_points]\n",
    "\n",
    "    # export patched slice\n",
    "    patched_slice_name = slice_details.replace('testing_slices/', 'patched_')\n",
    "    export_patched_slice(patched_slice_name.replace('.tif', '.png'), result)\n",
    "\n",
    "    # extract square patch images\n",
    "\n",
    "    patches, coords_ = extract_square_images(padded_image, shifted_points)\n",
    "\n",
    "    # Get patches across stains\n",
    "    \n",
    "    patches_across_stains, coords_across_stains = get_patches_across_stains(\n",
    "        patches,\n",
    "        coords_,\n",
    "        stain_images[0],\n",
    "        stain_images[1],\n",
    "        stain_images[2]\n",
    "    )\n",
    "\n",
    "    # save patches to output folder\n",
    "    save_patches(patches_across_stains, slice_name)\n",
    "\n",
    "    return patches_across_stains, patch_length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f934fc3",
   "metadata": {},
   "source": [
    "## Patching Across Stains (Adapted from Aryaman's Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0349dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_coords(ref_image, new_image, coords):\n",
    "    ref_y, ref_x = ref_image.shape[:2]\n",
    "    new_y, new_x = new_image.shape[:2]\n",
    "\n",
    "    xmin_norm = int(coords[0]/ref_x * new_x)\n",
    "    ymin_norm = int(coords[1]/ref_y * new_y)\n",
    "\n",
    "    xmax_norm = int(coords[2]/ref_x * new_x)\n",
    "    ymax_norm = int(coords[3]/ref_y * new_y)\n",
    "\n",
    "    return xmin_norm, ymin_norm, xmax_norm, ymax_norm\n",
    "\n",
    "def get_patches_across_stains(patches, coords, image1, image2, image3):\n",
    "    # Check the same region across all stains\n",
    "    patches_across_stains = []\n",
    "    coords_across_stains = []\n",
    "    print(\"Patches entering get_patches_across_stains:\", len(patches))\n",
    "    for i, patch in enumerate(patches):\n",
    "        min_x, min_y, max_x, max_y = coords[i]\n",
    "\n",
    "        x_dim = max_x - min_x\n",
    "        y_dim = max_y - min_y\n",
    "\n",
    "        patch_across_stains = []\n",
    "        coord_across_stains = []\n",
    "\n",
    "        patch_across_stains.append(image1[min_y:max_y, min_x:max_x])\n",
    "        coord_across_stains.append(coords[i])\n",
    "\n",
    "        coords_norm2 = normalize_coords(image1, image2, coords[i])\n",
    "        coord_across_stains.append(coords_norm2)\n",
    "\n",
    "        xmin_norm2, ymin_norm2, xmax_norm2, ymax_norm2 = coords_norm2\n",
    "        patch2_norm = image2[ymin_norm2:ymax_norm2, xmin_norm2:xmax_norm2]\n",
    "        patch_across_stains.append(cv2.resize(patch2_norm, (x_dim, y_dim)))\n",
    "\n",
    "        coords_norm3 = normalize_coords(image1, image3, coords[i])\n",
    "        coord_across_stains.append(coords_norm3)\n",
    "\n",
    "        xmin_norm3, ymin_norm3, xmax_norm3, ymax_norm3 = coords_norm3\n",
    "        patch3_norm = image3[ymin_norm3:ymax_norm3, xmin_norm3:xmax_norm3]\n",
    "        patch_across_stains.append(cv2.resize(patch3_norm, (x_dim, y_dim)))\n",
    "\n",
    "        # Check if the patch contains parts from all three images\n",
    "        if all(np.any(patch > 0) for patch in patch_across_stains):\n",
    "            # Check if the patch has between 5-80% black pixels - this is approximately the range we want\n",
    "            black_pixels = [np.sum(np.all(patch == [0, 0, 0], axis=-1)) for patch in patch_across_stains]\n",
    "            total_pixels = patch_across_stains[0].shape[0] * patch_across_stains[0].shape[1]\n",
    "            black_pixel_percentages = [black_pixel / total_pixels for black_pixel in black_pixels]\n",
    "\n",
    "            if all(percentage <= 0.8 for percentage in black_pixel_percentages):\n",
    "                patches_across_stains.append(patch_across_stains)\n",
    "                coords_across_stains.append(coord_across_stains)\n",
    "    print(\"Patches that passed filtering:\", len(patches_across_stains))\n",
    "\n",
    "    return patches_across_stains, coords_across_stains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b9fe2f",
   "metadata": {},
   "source": [
    "## Mask Alignment Using Affine Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cb0b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_masks(fixed_mask, moving_mask, warp_mode=cv2.MOTION_AFFINE, number_of_iterations=5000, termination_eps=1e-10):\n",
    "    fixed_gray = cv2.cvtColor(fixed_mask, cv2.COLOR_BGR2GRAY) if len(fixed_mask.shape) == 3 else fixed_mask\n",
    "    moving_gray = cv2.cvtColor(moving_mask, cv2.COLOR_BGR2GRAY) if len(moving_mask.shape) == 3 else moving_mask\n",
    "\n",
    "    fixed_gray = fixed_gray.astype(np.float32)\n",
    "    moving_gray = moving_gray.astype(np.float32)\n",
    "\n",
    "    if warp_mode == cv2.MOTION_HOMOGRAPHY:\n",
    "        warp_matrix = np.eye(3, 3, dtype=np.float32)\n",
    "    else:\n",
    "        warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, number_of_iterations, termination_eps)\n",
    "\n",
    "    cc, warp_matrix = cv2.findTransformECC(fixed_gray, moving_gray, warp_matrix, warp_mode, criteria)\n",
    "\n",
    "    sz = fixed_mask.shape\n",
    "    if warp_mode == cv2.MOTION_HOMOGRAPHY:\n",
    "        aligned_mask = cv2.warpPerspective(moving_mask, warp_matrix, (sz[1], sz[0]), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "    else:\n",
    "        aligned_mask = cv2.warpAffine(moving_mask, warp_matrix, (sz[1], sz[0]), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "\n",
    "    return aligned_mask\n",
    "\n",
    "def align_all_masks(he_mask, melan_mask, sox10_mask):\n",
    "    aligned_melan = align_masks(he_mask, melan_mask)\n",
    "    aligned_sox10 = align_masks(he_mask, sox10_mask)\n",
    "    return he_mask, aligned_melan, aligned_sox10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ba0652",
   "metadata": {},
   "source": [
    "## Patch Export Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8313859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"testing_slices\" # put folder path here\n",
    "output_path = 'testing_slices/patch_outputs'\n",
    "\n",
    "# Dictionary to store matches\n",
    "cases = {}\n",
    "\n",
    "# Iterate over files in the folder\n",
    "for filename in os.listdir(image_folder):\n",
    "    match = re.match(r\"case_(\\d+)_match_(\\d+)_(h&e|melan|sox10).*\\.(png|tif)\", filename)\n",
    "    if match:\n",
    "        case_number, match_number, scan_type, extension = match.groups()\n",
    "        case_number, match_number = int(case_number), int(match_number)  # Convert to int for sorting\n",
    "\n",
    "        if case_number not in cases:\n",
    "            cases[case_number] = {}\n",
    "\n",
    "        if match_number not in cases[case_number]:\n",
    "            cases[case_number][match_number] = {}\n",
    "\n",
    "        if scan_type not in cases[case_number][match_number]:\n",
    "            cases[case_number][match_number][scan_type] = {\"mask\": \"None\", \"slice\": \"None\"}\n",
    "\n",
    "        if extension == \"png\":\n",
    "            cases[case_number][match_number][scan_type][\"mask\"] = os.path.join(image_folder, filename)\n",
    "\n",
    "        elif extension == \"tif\":\n",
    "            cases[case_number][match_number][scan_type][\"slice\"] = os.path.join(image_folder, filename)\n",
    "\n",
    "# Build list of full triplets\n",
    "matched_triplets = []\n",
    "for case in cases.values():\n",
    "    for match in case.values():\n",
    "        if all(stain in match for stain in ['h&e', 'melan', 'sox10']):\n",
    "            h_mask = match['h&e'].get('mask')\n",
    "            h_slice = match['h&e'].get('slice')\n",
    "            m_mask = match['melan'].get('mask')\n",
    "            m_slice = match['melan'].get('slice')\n",
    "            s_mask = match['sox10'].get('mask')\n",
    "            s_slice = match['sox10'].get('slice')\n",
    "\n",
    "            if all([h_mask, h_slice, m_mask, m_slice, s_mask, s_slice]):\n",
    "                matched_triplets.append((h_mask, h_slice, m_mask, m_slice, s_mask, s_slice))\n",
    "\n",
    "# delete any patches that are already in the directory\n",
    "empty_folder()\n",
    "\n",
    "# Run patching and exporting over triplets\n",
    "for i, triplet in enumerate(matched_triplets, 1):\n",
    "    h_mask, h_slice, m_mask, m_slice, s_mask, s_slice = triplet\n",
    "\n",
    "    # Use H&E mask to generate patch coordinates\n",
    "    image1 = cv2.imread(h_mask)\n",
    "    image1_gray = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    Otsu_threshold, epithelium_mask_2D = cv2.threshold(image1_gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    case_number = re.search(r\"case_(\\d+)_match_(\\d+)\", h_mask).groups()\n",
    "    case_number = tuple(map(int, case_number))\n",
    "\n",
    "    # Read original RGB slice images\n",
    "    he_img = cv2.cvtColor(cv2.imread(h_slice), cv2.COLOR_BGR2RGB)\n",
    "    melan_img = cv2.cvtColor(cv2.imread(m_slice), cv2.COLOR_BGR2RGB)\n",
    "    sox10_img = cv2.cvtColor(cv2.imread(s_slice), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Run patching pipeline\n",
    "    triplet_patches, patch_length = patching_export(\n",
    "        epithelium_mask_2D,\n",
    "        h_mask,\n",
    "        h_slice,\n",
    "        [he_img, melan_img, sox10_img]\n",
    "    )\n",
    "\n",
    "    # Save output patches\n",
    "    file_name = os.path.basename(h_mask).replace('mask', '').replace('.png', '')\n",
    "    for j, triplet in enumerate(triplet_patches):\n",
    "        for k, stain_patch in enumerate(triplet):\n",
    "            stain_name = [\"h&e\", \"melan\", \"sox10\"][k]\n",
    "            output_path = os.path.join(\"testing_slices\", \"patch_outputs\", f\"{file_name}_patch{j}_{stain_name}.png\")\n",
    "            cv2.imwrite(output_path, stain_patch)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
